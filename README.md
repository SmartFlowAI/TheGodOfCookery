<div align="center">
  <img src="https://github.com/zhanghui-china/intro_myself/blob/main/images/shishen.jpg" width="600"/>
  <br /><br />

![license](https://img.shields.io/github/license/zhanghui-china/intro_myself.svg)  [![issue resolution](https://img.shields.io/github/issues-closed-raw/zhanghui-china/intro_myself)](https://github.com/zhanghui-china/intro_myself/issues)   [![open issues](https://img.shields.io/github/issues-raw/zhanghui-china/intro_myself)](https://github.com/zhanghui-china/intro_myself/issues)

ğŸ” æ¢ç´¢æˆ‘ä»¬çš„æ¨¡å‹ï¼š
[![Static Badge](https://img.shields.io/badge/-gery?style=social&label=ğŸ¤–%20ModelScope)](https://www.modelscope.cn/models/zhanghuiATchina/zhangxiaobai_shishen2_full/summary)

</div>
</p>

## ä»‹ç»

æœ¬APPç”¨äºå‚åŠ  ã€ä¹¦ç”ŸÂ·æµ¦è¯­å¤§æ¨¡å‹å®æˆ˜è¥ã€‘çš„é¡¹ç›®å®æˆ˜ã€‚ç”¨äºå®ç°å’¨è¯¢èœè°±çš„å¯¹è¯ã€‚

æœ¬APPçš„åŸºæœ¬æ€æƒ³ï¼Œæ˜¯åŸºäºInternLMçš„å¯¹è¯æ¨¡å‹ï¼Œé‡‡ç”¨ XiaChuFang Recipe Corpus æä¾›çš„1,520,327ç§ä¸­å›½é£Ÿè°±è¿›è¡Œå¾®è°ƒï¼Œç”Ÿæˆé£Ÿè°±æ¨¡å‹ã€‚ æ¨¡å‹å­˜æ”¾åœ¨modelscopeä¸Šï¼Œåº”ç”¨éƒ¨ç½²åœ¨openxlabä¸Šã€‚ä¸ºæ­¤æ„Ÿè°¢é­”æ­ç¤¾åŒºæä¾›å…è´¹çš„æ¨¡å‹å­˜æ”¾ç©ºé—´ï¼Œæ„Ÿè°¢OpenXLabæä¾›åº”ç”¨éƒ¨ç½²ç¯å¢ƒåŠGPUèµ„æºã€‚

æœ¬APPå€Ÿç”¨äº†å¶åƒå‘¨æ˜Ÿæ˜Ÿã€Šé£Ÿç¥ã€‹çš„ç”µå½±æˆªå›¾ï¼Œä¸ç”¨äºå•†ä¸šç›®çš„ã€‚ä»…ä»…ç”±æ­¤è¡¨è¾¾å¯¹å‘¨æ˜Ÿæ˜Ÿçš„å°Šæ•¬ä¹‹æƒ…ã€‚

æœ¬APPæä¾›çš„å›ç­”ä»…ä¾›å‚è€ƒï¼Œä¸ä½œä¸ºæ­£å¼èœè°±çš„çœŸå®åˆ¶ä½œæ­¥éª¤ã€‚ç”±äºå¤§æ¨¡å‹çš„â€œå¹»è§‰â€ç‰¹æ€§ï¼Œå¾ˆå¯èƒ½æœ‰äº›é£Ÿè°±ä¼šç»™ç”¨æˆ·å¸¦æ¥å¿ƒç†æˆ–ç”Ÿç†ä¸Šçš„ä¸åˆ©å½±å“ï¼Œå¸Œæœ›ç”¨æˆ·ä»…è®¤ä¸ºè¿™æ˜¯å‘¨æ˜Ÿæ˜Ÿè¿œç¨‹æ•™è‚²å­¦é™¢å­¦å‘˜å¼ å°ç™½è·Ÿå¤§å®¶å¼€çš„ä¸€æ¬¡æ— å˜å¤´çš„ç©ç¬‘ï¼Œåˆ‡å‹¿ä¸Šçº²ä¸Šçº¿ã€‚



## æ›´æ–°è¯´æ˜

- [2024.1.30] åŸºäºäºŒä»£150ä¸‡èœè°±å¾®è°ƒçš„æ¨¡å‹å’ŒAPPå‘å¸ƒã€‚ï¼ˆä½¿ç”¨InternStudio+A100 1/4X2 40Gæ˜¾å­˜å¾®è°ƒï¼Œ1.25 15:46-1.30 12:25ï¼Œå¾®è°ƒå†æ—¶4å¤©20å°æ—¶39åˆ†é’Ÿï¼‰
- [2024.1.28] åŸºäºä¸€ä»£150ä¸‡èœè°±å¾®è°ƒçš„æ¨¡å‹å’ŒAPPå‘å¸ƒã€‚ï¼ˆä½¿ç”¨WSL+Ubuntu22.04+RTX4090 24Gæ˜¾å­˜å¾®è°ƒï¼Œ1.26 18:40-1.28 13:46å†æ—¶1å¤©19å°æ—¶6åˆ†é’Ÿï¼‰ã€‚



## å¿«é€Ÿä¸Šæ‰‹



### å®‰è£…

1. å‡†å¤‡ Python è™šæ‹Ÿç¯å¢ƒï¼š

   ```bash
   conda create -n xtunernew python=3.10 -y
   conda activate xtunernew
   ```

2. å…‹éš†è¯¥ä»“åº“ï¼š

   ```shell
   git clone https://github.com/zhanghui-china/intro_myself.git
   cd ./intro_myself
   ```

3. å®‰è£…Pytorchå’Œä¾èµ–åº“ï¼š

   ```shell
   conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia
   pip install -r requirements.txt
   ```



### è®­ç»ƒ

â€‹		æœ¬é¡¹ç›®ä¸€ä»£æ¨¡å‹ ä½¿ç”¨ xtuner0.1.9 è®­ç»ƒï¼Œåœ¨ internlm-chat-7b ä¸Šè¿›è¡Œå¾®è°ƒï¼Œ[æ¨¡å‹åœ°å€](https://www.modelscope.cn/models/zhanghuiATchina/zhangxiaobai_shishen_full/summary)

â€‹		äºŒä»£æ¨¡å‹ ä½¿ç”¨ xtuner0.1.13 è®­ç»ƒï¼Œåœ¨ internlm2-chat-7b ä¸Šè¿›è¡Œå¾®è°ƒï¼Œ[æ¨¡å‹åœ°å€](https://www.modelscope.cn/models/zhanghuiATchina/zhangxiaobai_shishen2_full/summary)

1. å¾®è°ƒæ–¹æ³•å¦‚ä¸‹

   ```shell
   xtuner train ${YOUR_CONFIG} --deepspeed deepspeed_zero2
   ```

   - `--deepspeed` è¡¨ç¤ºä½¿ç”¨ [DeepSpeed](https://github.com/microsoft/DeepSpeed) ğŸš€ æ¥ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ã€‚XTuner å†…ç½®äº†å¤šç§ç­–ç•¥ï¼ŒåŒ…æ‹¬ ZeRO-1ã€ZeRO-2ã€ZeRO-3 ç­‰ã€‚å¦‚æœç”¨æˆ·æœŸæœ›å…³é—­æ­¤åŠŸèƒ½ï¼Œè¯·ç›´æ¥ç§»é™¤æ­¤å‚æ•°ã€‚

2. å°†ä¿å­˜çš„ `.pth` æ¨¡å‹ï¼ˆå¦‚æœä½¿ç”¨çš„DeepSpeedï¼Œåˆ™å°†ä¼šæ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼‰è½¬æ¢ä¸º LoRA æ¨¡å‹ï¼š

   ```shell
   export MKL_SERVICE_FORCE_INTEL=1
   xtuner convert pth_to_hf ${YOUR_CONFIG} ${PTH} ${LoRA_PATH}
   ```

   3.å°†LoRAæ¨¡å‹åˆå¹¶å…¥ HuggingFace æ¨¡å‹ï¼š

```shell
xtuner convert merge ${Base_PATH} ${LoRA_PATH} ${SAVE_PATH}
```



### å¯¹è¯

```shell
xtuner chat ${SAVE_PATH} [optional arguments]
```

å‚æ•°ï¼š

- `--prompt-template`: ä¸€ä»£æ¨¡å‹ä½¿ç”¨ internlm_chatï¼ŒäºŒä»£ä½¿ç”¨  internlm2_chatã€‚
- `--system`: æŒ‡å®šå¯¹è¯çš„ç³»ç»Ÿå­—æ®µã€‚
- `--bits {4,8,None}`: æŒ‡å®š LLM çš„æ¯”ç‰¹æ•°ã€‚é»˜è®¤ä¸º fp16ã€‚
- `--no-streamer`: æ˜¯å¦ç§»é™¤ streamerã€‚
- `--top`: å¯¹äºäºŒä»£æ¨¡å‹ï¼Œå»ºè®®ä¸º0.8ã€‚
- `--temperature`: å¯¹äºäºŒä»£æ¨¡å‹ï¼Œå»ºè®®ä¸º0.8ã€‚
- `--repetition-penalty`: å¯¹äºäºŒä»£æ¨¡å‹ï¼Œå»ºè®®ä¸º1.002ï¼Œå¯¹äºä¸€ä»£æ¨¡å‹å¯ä¸å¡«ã€‚
- æ›´å¤šä¿¡æ¯ï¼Œè¯·æ‰§è¡Œ `xtuner chat -h` æŸ¥çœ‹ã€‚

## æ¼”ç¤º

Demo è®¿é—®åœ°å€ï¼šhttps://openxlab.org.cn/apps/detail/zhanghui-china/nlp_shishen

<div align="center">
  <img src="https://github.com/zhanghui-china/intro_myself/blob/main/images/answer001.png" width="600"/>
  <br />
  <img src="https://github.com/zhanghui-china/intro_myself/blob/main/images/answer002.png" width="600"/>
  <br />
</div>



## æ¨¡å‹

[openxlabä¸€ä»£æ¨¡å‹](https://openxlab.org.cn/models/detail/zhanghui-china/zhangxiaobai_shishen_full)    <br />
[openxlabäºŒä»£æ¨¡å‹](https://openxlab.org.cn/models/detail/zhanghui-china/zhangxiaobai_shishen2_full)    <br />

```shell
import torch
from modelscope import AutoTokenizer, AutoModelForCausalLM
from tools.transformers.interface import GenerationConfig, generate_interactive

model_name_or_path = "zhanghuiATchina/zhangxiaobai_shishen_full" #å¯¹äºäºŒä»£æ¨¡å‹æ”¹ä¸º zhangxiaobai_shishen2_full

tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=True, torch_dtype=torch.bfloat16, device_map='auto')
model = model.eval()

messages = []
generation_config = GenerationConfig(max_length=max_length, top_p=0.8, temperature=0.8, repetition_penalty=1.002)

response, history = model.chat(tokenizer, "ä½ å¥½", history=[])
print(response)
response, history = model.chat(tokenizer, "é…¸èœé±¼æ€ä¹ˆåš", history=history)
print(response)
```



## å·²çŸ¥é—®é¢˜å’Œæœªæ¥è§„åˆ’

1.ç›®å‰åŸºäºäºŒä»£æ¨¡å‹å¾®è°ƒåçš„é£Ÿè°±æ¨¡å‹ï¼Œå¯èƒ½è¿˜ä¼šä¸å®šæœŸå‡ºç°æ­»å¾ªç¯åå­—çš„é—®é¢˜ã€‚å³ä¾¿åŠ äº†repetition_penalty=1.002å‚æ•°ä¹Ÿä¸èƒ½å®Œå…¨é˜»æ­¢è¿™ä¸€ä¸å¯æ§çš„è¡Œä¸ºã€‚è€Œä¸”ï¼Œå½“repetition_penalty=1.05æ—¶ï¼Œç­”æ¡ˆä¼šå‡ºç°ä¸ç¬¦åˆé¢„æœŸè¾“å‡ºçš„æ ¼å¼ã€‚è¯´æ˜æœ¬æ¨¡å‹è¿˜æ˜¯å¤ªå¹´è½»ã€‚éœ€è¦ä¸æ–­å®Œå–„è°ƒæ•™çš„æ–¹æ³•ï¼ˆè¯´ä¸å®šä¹Ÿéœ€è¦åŸºå‡†æ¨¡å‹ä¸æ–­åœ°æé«˜ç›¸å…³çš„èƒ½åŠ›ï¼‰<br />

2.ç›®å‰å¯¹æé—®é‡‡ç”¨ç®€å•çš„è¿‡æ»¤æ–¹å¼ï¼Œå¦‚æœç”¨æˆ·æé—®çš„å…³é”®è¯ä¸­æ²¡æœ‰â€œæ€ä¹ˆåšâ€ã€"åšæ³•"ã€â€œé£Ÿè°±â€ç­‰å­—æ ·ï¼Œå°±è¦æ±‚ç”¨æˆ·æä¾›ç›¸å…³çš„æŒ‡ä»¤ï¼Œå¦åˆ™ä¸€ç›´ä¼šæç¤ºé”™è¯¯ã€‚ä»Šåå¯è€ƒè™‘é‡‡ç”¨å¤šè½®å¯¹è¯æ¥è·å–æ˜ç¡®çš„èœåä¿¡æ¯ï¼ˆå¦‚å…ˆé—®æƒ³åƒä»€ä¹ˆèœâ€”â€”æ¯”å¦‚å·èœæˆ–è€…ä¸œåŒ—èœï¼Œå†é—®ä»€ä¹ˆå£å‘³â€”â€”æ¯”å¦‚åç”œè¿˜æ˜¯åè¾£ç­‰ç­‰ï¼‰ï¼Œä»¥ä¾¿æä¾›ç²¾ç¡®çš„èœè°±ä¿¡æ¯ã€‚ <br />  

3.ä»Šåä¼šè€ƒè™‘å¯¹æ¥æ–‡ç”Ÿå›¾çš„åº”ç”¨ï¼Œåœ¨ç”Ÿæˆèœè°±çš„åˆ¶ä½œè¿‡ç¨‹ä¹‹åï¼ŒåŒæ—¶ç”Ÿæˆä¸€å‰¯è¯¥èœçš„ç…§ç‰‡ï¼Œæ–‡å›¾å¹¶èŒ‚å±•ç¤ºä¿¡æ¯ã€‚  <br />



4.çœ‹çœ‹èƒ½ä¸èƒ½å°†æç¤ºç¬¦å·¥ç¨‹åº”ç”¨åˆ°é¡¹ç›®é‡Œé¢å»ã€‚è¿™æ¬¡è™½ç„¶å†™äº†promptï¼Œä½†æ˜¯æ„Ÿè§‰ç›¸å…³çš„äº¤äº’ç»“æœå¹¶æ²¡æœ‰ä¸¥æ ¼æŒ‰ç…§promptèµ°ã€‚ <br />






## å®è·µæ–‡æ¡£

[ä¸€ä»£å®è·µ](https://zhuanlan.zhihu.com/p/678019309)  <br />
[äºŒä»£å®è·µ](https://zhuanlan.zhihu.com/p/678376843)  <br />

[å®è·µè§†é¢‘](https://www.bilibili.com/video/BV1Ut421W7Qg)  <br />



## å…³äºä½œè€…

é¡¹ç›®ä½œè€…ï¼šå¼ å°ç™½ï¼Œå­—å¤§ç™½ï¼Œä¼˜è´¨å›å¤å®¶ã€‚æ–œæ é’å¹´ï¼Œç²¾åŠ›å……æ²›ã€‚ç®€ç§°é’¢ç­‹ã€‚ [åšå®¢åœ°å€](https://www.zhihu.com/people/zhanghui_china)




## å¼€æºè®¸å¯è¯

è¯¥é¡¹ç›®é‡‡ç”¨ [Apache License 2.0 å¼€æºè®¸å¯è¯](LICENSE.txt)ã€‚
