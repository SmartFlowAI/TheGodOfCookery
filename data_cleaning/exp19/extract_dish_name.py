import json
from openai import OpenAI
import requests

prompt = """ä½ æ˜¯ä¸€ä¸ªèœå“åç§°æå–å™¨ï¼Œç†Ÿæ‚‰å„ç§èœå“åç§°ï¼Œç°åœ¨ç»™ä½ ä¸€äº›å«æœ‰å†—ä½™è¯è¯­çš„èœå“åç§°ï¼Œå†—ä½™çš„è¯è¯­å¯èƒ½æ˜¯emojiæˆ–ä¸å¿…è¦çš„ä¿®é¥°è¯­ã€‚
ä½ éœ€è¦æŒ‰ç…§â€œåºå· æå–ç»“æœâ€è¾“å‡ºä½ çš„æå–ç»“æœï¼Œä¾‹å¦‚ï¼š
è¾“å…¥ï¼š
10å¯¸æˆšé£è›‹ç³•ï¼Œäº‘æœµèˆ¬æŸ”è½¯
10å¯¸æŠ«è¨ğŸ•ä¸€ä¸ªçš„åšæ³•
è¾“å‡ºï¼š
1 10å¯¸æˆšé£è›‹ç³•
2 10å¯¸æŠ«è¨
ç°åœ¨ï¼Œè¯·ä½ æå–ä»¥ä¸‹è¾“å…¥çš„èœå“åç§°,æ³¨æ„ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šæ ¼å¼è¾“å‡ºï¼Œä¸è¦è¾“å‡ºå¤šä½™å­—ç¬¦ï¼š
{input}
"""

data_path = '../data/recipe_corpus_dedup.jsonl' # ä¿®æ”¹æˆä½ çš„è·¯å¾„
batch_size = 20 # æ¯æ¬¡é€å…¥å¤§æ¨¡å‹å¤„ç†çš„æ•°æ®é‡ï¼Œå¯è§†æƒ…å†µä¿®æ”¹

'''
Stage 1: Read the data
'''
def read_data():
    with open(data_path, 'r',encoding='utf-8') as f:
        lines = f.readlines()
        names = [json.loads(l)['name'] for l in lines]
    return names

names = read_data()

'''
Stage 2: Load the data to the prompt
'''
def generate_prompt():
    global names
    i = 0
    while i < len(names[:200]):
        batch = '\n'.join(names[i:i+batch_size])
        i += batch_size
        yield batch


'''
Stage 3: Feed into the LLMs
'''

def deepseek():
    global names
    with open('./deepseek_key.txt','r',encoding='utf-8') as f:
        DEEPSEEK_KEY = f.readline()
    extracted_names = []
    client = OpenAI(api_key=DEEPSEEK_KEY, base_url="https://api.deepseek.com/")
    i = 0
    for batch in generate_prompt():
        final_prompt = prompt.replace('{input}',batch)
        response = client.chat.completions.create(
            model='deepseek-chat',
            messages=[
                 {"role": "system", "content": ""},
                 {"role": "user", "content": final_prompt},
            ]
        )
        names_with_idx = response.choices[0].message.content.split('\n') # å¾—åˆ° â€œåºå· èœå“åç§°â€
        for name in names_with_idx:
            splitted_name_idx = name.split(' ') # åˆ†å‡º â€œèœå“åç§°â€ è¿™ä¸€é¡¹
            if len(splitted_name_idx) != 2: # å›ç­”æ ¼å¼æœ‰è¯¯ï¼ŒåŠ å…¥åŸåç§°
                print(name + 'æ ¼å¼ä¸æ­£ç¡®, åŠ å…¥åŸåç§°')
                extracted_names.append(names[i])
            else:
                extracted_names.append(splitted_name_idx[1])
        i += 1
    return extracted_names
    
def internlm2_20b():
    extracted_names = []
    i = 0
    for batch in generate_prompt():
        final_prompt = prompt.replace('{input}','\n'.join(batch))
        """
        TODO: è°ƒç”¨internlm2-chat-20bæ¥å£
        """
        name_with_idx = [] # æ¨¡å‹çš„å›ç­”
        for name in name_with_idx:
            splitted_name_idx = name.split(' ') # åˆ†å‡º â€œèœå“åç§°â€ è¿™ä¸€é¡¹
            if len(splitted_name_idx) != 2: # å›ç­”æ ¼å¼æœ‰è¯¯ï¼ŒåŠ å…¥åŸåç§°
                print(name + 'æ ¼å¼ä¸æ­£ç¡®, åŠ å…¥åŸåç§°')
                extracted_names.append(names[i])
            else:
                extracted_names.append(splitted_name_idx[1])
        i += 1
    return extracted_names

'''
TODO: Stage 4: Store the extracted names to compare
'''


for batch in generate_prompt():
    print(prompt.replace('{input}',batch))